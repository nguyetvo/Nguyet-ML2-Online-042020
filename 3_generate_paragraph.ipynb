{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.3"
    },
    "colab": {
      "name": "3 - generate paragraph.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nguyetvo/Nguyet-ML2-Online-042020/blob/master/3_generate_paragraph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeGW0eTVzItH",
        "colab_type": "text"
      },
      "source": [
        "# Text Generation\n",
        "\n",
        "It is now time to generate some text from the models we trained!\n",
        "\n",
        "As a recap:\n",
        " - we trained a **first bidirectional LSTM model** to predict the next word of a given sequence of 30 words.\n",
        " - we train a **doc2vec model** for the whole input text as space, sentence based,\n",
        " - we trained a **second bidirectional LSTM model** to predict the best vectorized-sentence, following a sequence of 15 vectorized-phrases.\n",
        " \n",
        "So, what will be the process of our text generation ? We have first to provide a seed of 15 sentences, that contain at least 30 words. then:\n",
        " 1. using the last 30 words of the seed, we generate 10 candidates sentences.\n",
        " 2. we infer their vectors using the doc2vec model,\n",
        " 3. we calculate the \"best vector\" for the sentence following the 15 phrases of the seed,\n",
        " 4. we compare the infered vectors with the \"best vector\", and pick-up the closest one.\n",
        " 5. we add the generated sentence corresponding to this vector at the end of the seed, as the next sentence of the text.\n",
        " 6. then, we loop over the process.\n",
        " \n",
        "## 0. import libraries and parameters\n",
        "\n",
        "In order to start, we have to import our models and retrieve our vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "DR_j-dfkzItK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "import os\n",
        "import scipy\n",
        "from six.moves import cPickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "r4a87XX0zIta",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "save_dir = 'save' # directory to store models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "qZ730rxJzIth",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import spacy, and french model\n",
        "import spacy\n",
        "nlp = spacy.load('fr')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dCpGmOVzItp",
        "colab_type": "code",
        "colab": {},
        "outputId": "6015cf23-13e0-4b0d-966f-c0f76d6b7434"
      },
      "source": [
        "#import gensim library\n",
        "import gensim\n",
        "from gensim.models.doc2vec import LabeledSentence\n",
        "\n",
        "#load the doc2vec model\n",
        "print(\"loading doc2Vec model...\")\n",
        "d2v_model = gensim.models.doc2vec.Doc2Vec.load('./data/doc2vec.w2v')\n",
        "\n",
        "print(\"model loaded!\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading doc2Vec model...\n",
            "model loaded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eca74ktzIty",
        "colab_type": "code",
        "colab": {},
        "outputId": "21db8b5d-6a6d-4b16-e3f1-900d1f59f71b"
      },
      "source": [
        "#load vocabulary\n",
        "print(\"loading vocabulary...\")\n",
        "vocab_file = os.path.join(save_dir, \"words_vocab.pkl\")\n",
        "\n",
        "with open(os.path.join(save_dir, 'words_vocab.pkl'), 'rb') as f:\n",
        "        words, vocab, vocabulary_inv = cPickle.load(f)\n",
        "\n",
        "vocab_size = len(words)\n",
        "print(\"vocabulary loaded !\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading vocabulary...\n",
            "vocabulary loaded !\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rBoJn84zIt9",
        "colab_type": "code",
        "colab": {},
        "outputId": "dd82787c-6d63-485b-eb07-472efc97fc06"
      },
      "source": [
        "from keras.models import load_model\n",
        "# load the keras models\n",
        "print(\"loading word prediction model...\")\n",
        "model = load_model(save_dir + \"/\" + 'my_model_gen_sentences_lstm.final.hdf5')\n",
        "print(\"model loaded!\")\n",
        "print(\"loading sentence selection model...\")\n",
        "model_sequence = load_model(save_dir + \"/\" + 'my_model_sequence_lstm.final.hdf5')\n",
        "print(\"model loaded!\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading word prediction model...\n",
            "model loaded!\n",
            "loading sentence selection model...\n",
            "model loaded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2Uv1p7wzIuQ",
        "colab_type": "text"
      },
      "source": [
        "# 1. Functions to generate Candidates Sentences\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLS02P4PzIuS",
        "colab_type": "text"
      },
      "source": [
        "To improve the text generation, and tune a bit the word prediction, we introduce a specific function to pick-up words from our vocabulary.\n",
        "\n",
        "We will not take the words with the highest prediction (or the generation of text will be boring), but would like to insert some uncertainties, and let the solution, sometime, to pick-up words with less good prediction.\n",
        "\n",
        "That is the purpose of the function **sample()**, that will draw randomly a word from our vocabulary.\n",
        "\n",
        "However, the probability for a word to be drawn will depends directly on its probability to be the next word, thanks to our first bidirectional LSTM Model.\n",
        "\n",
        "In order to tune this probability, we introduce a \"temperature\" to smooth or sharpen its value.\n",
        " - **if _temperature = 1.0_**, the probability for a word to be drawn is equal to the probability for the word to be the next one in the sequence (output of the owrd prediction model),\n",
        " - **if _temperature_ is big (much bigger than 1)**, the range of probabilities is shorten: the probabilities for all words to be the next one is closer to 1. More variety of words will be picked-up from the vocabulary.\n",
        " - **if _temperatune_ is small (close to 0)**, small probabilities will be avoided (they will be set closed to 0). Less words will be picked-up from the vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "JktHpN19zIuT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ybqgn0gPzIud",
        "colab_type": "text"
      },
      "source": [
        "The **create_seed()** function is usefull to prepare seed sequences, especially if the number of words in the seed phrase is lower than the espected number for a sequence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "Tak9XPtPzIud",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_seed(seed_sentences,nb_words_in_seq=20, verbose=False):\n",
        "    #initiate sentences\n",
        "    generated = ''\n",
        "    sentence = []\n",
        "    \n",
        "    #fill the sentence with a default word\n",
        "    for i in range (nb_words_in_seq):\n",
        "        sentence.append(\"le\")\n",
        "\n",
        "    seed = seed_sentences.split()\n",
        "    \n",
        "    if verbose == True : print(\"seed: \",seed)\n",
        "\n",
        "    for i in range(len(sentence)):\n",
        "        sentence[nb_words_in_seq-i-1]=seed[len(seed)-i-1]\n",
        "        #print(i, sentence)\n",
        "\n",
        "    generated += ' '.join(sentence)\n",
        "    \n",
        "    if verbose == True : print('Generating text with the following seed: \"' + ' '.join(sentence) + '\"')\n",
        "\n",
        "    return [generated, sentence]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9R5UQN_OzIuk",
        "colab_type": "text"
      },
      "source": [
        "the function **generate_phrase()** is used to create the next phrase of a given sentence.\n",
        "\n",
        "It requires as inputs:\n",
        " - the previous sentence,\n",
        " - the maximum number of words in the phrase,\n",
        " - the temperature of the sample function.\n",
        " \n",
        "If a punctuation word is reached before the maximum number of the words, the function ends."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "3FfUFSgIzIul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_phrase(sentence, max_words = 50, nb_words_in_seq=20, temperature=1, verbose = False):\n",
        "    generated = \"\"\n",
        "    words_number = max_words - 1\n",
        "    ponctuation = [\".\",\"?\",\"!\",\":\",\"…\"]\n",
        "    seq_length = nb_words_in_seq\n",
        "    #sentence = []\n",
        "    is_punct = False\n",
        "    \n",
        "    #generate the text\n",
        "    for i in range(words_number):\n",
        "        #create the vector\n",
        "        x = np.zeros((1, seq_length, vocab_size))\n",
        "        for t, word in enumerate(sentence):\n",
        "            #print(t, word, vocab[word])\n",
        "            x[0, nb_words_in_seq-len(sentence)+t, vocab[word]] = 1.\n",
        "        #print(x.shape)\n",
        "\n",
        "        #calculate next word\n",
        "        preds = model.predict(x, verbose=0)[0]\n",
        "        next_index = sample(preds, temperature)\n",
        "        next_word = vocabulary_inv[next_index]\n",
        "        \n",
        "        if verbose == True:\n",
        "            predv = np.array(preds)\n",
        "            #arr = np.array([1, 3, 2, 4, 5])\n",
        "            wi = predv.argsort()[-3:][::-1]\n",
        "            print(\"potential next words: \", vocabulary_inv[wi[0]], vocabulary_inv[wi[1]], vocabulary_inv[wi[2]])\n",
        "\n",
        "        #add the next word to the text\n",
        "        if is_punct == False:\n",
        "            if next_word in ponctuation:\n",
        "                is_punct = True\n",
        "            generated += \" \" + next_word\n",
        "            # shift the sentence by one, and and the next word at its end\n",
        "            sentence = sentence[1:] + [next_word]\n",
        "\n",
        "    return(generated, sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVqp-_u6zIuu",
        "colab_type": "text"
      },
      "source": [
        "the function **define_phrases_candidates()** provides a list of potential phrases, for a given previous sentence and a specific temperature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "HB21Ez6pzIuu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def define_phrases_candidates(sentence, max_words = 50,\\\n",
        "                              nb_words_in_seq=20, \\\n",
        "                              temperature=1, \\\n",
        "                              nb_candidates_sents=10, \\\n",
        "                              verbose = False):\n",
        "    phrase_candidate = []\n",
        "    generated_sentence = \"\"\n",
        "    for i in range(nb_candidates_sents):\n",
        "        generated_sentence, new_sentence = generate_phrase(sentence, \\\n",
        "                                                           max_words = max_words, \\\n",
        "                                                           nb_words_in_seq = nb_words_in_seq, \\\n",
        "                                                           temperature=temperature, \\\n",
        "                                                           verbose = False)\n",
        "        phrase_candidate.append([generated_sentence, new_sentence])\n",
        "    \n",
        "    if verbose == True :\n",
        "        for phrase in phrase_candidate:\n",
        "            print(\"   \" , phrase[0])\n",
        "    return phrase_candidate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QX1zVvFxzIuz",
        "colab_type": "text"
      },
      "source": [
        "# 2. Functions to select the best sentence\n",
        "\n",
        "the **create_sentences()** function generate a sequence of words (a list) for a given spacy doc item.\n",
        "\n",
        "It will be used to create a sequence of words from a single phrase."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "w_qADL_lzIu0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_sentences(doc):\n",
        "    ponctuation = [\".\",\"?\",\"!\",\":\",\"…\"]\n",
        "    sentences = []\n",
        "    sent = []\n",
        "    for word in doc:\n",
        "        if word.text not in ponctuation:\n",
        "            if word.text not in (\"\\n\",\"\\n\\n\",'\\u2009','\\xa0'):\n",
        "                sent.append(word.text.lower())\n",
        "        else:\n",
        "            sent.append(word.text.lower())\n",
        "            if len(sent) > 1:\n",
        "                sentences.append(sent)\n",
        "            sent=[]\n",
        "    return sentences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJdsK9k5zIu5",
        "colab_type": "text"
      },
      "source": [
        "the **generate_training_vector()** function is used to predict the next vectorized-sentence for a given sequence of vectorized-sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "HoTg5ZhFzIu5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_training_vector(sentences_list, verbose = False):\n",
        "    if verbose == True : print(\"generate vectors for each sentence...\")\n",
        "    seq = []\n",
        "    V = []\n",
        "\n",
        "    for s in sentences_list:\n",
        "        #infer the vector of the sentence, from the doc2vec model\n",
        "        v = d2v_model.infer_vector(create_sentences(nlp(s))[0], alpha=0.001, min_alpha=0.001, steps=10000)\n",
        "    #create the vector array for the model\n",
        "        V.append(v)\n",
        "    V_val=np.array(V)\n",
        "    #expand dimension to fit the entry of the model : that's the training vector\n",
        "    V_val = np.expand_dims(V_val, axis=0)\n",
        "    if verbose == True : print(\"Vectors generated!\")\n",
        "    return V_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dW8T-FVozIu-",
        "colab_type": "text"
      },
      "source": [
        "The **select_next_phrase()** function allows us to pick-up the best candidates for the next phrase.\n",
        "\n",
        "First, it calculates the vector for each candidates.\n",
        "\n",
        "Then, based on the vector generated by the function **generate_training_vector()**, it performs a cosine similarity with them and pick the one with the biggest similarity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "0cor4x20zIu_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def select_next_phrase(model, V_val, candidate_list, verbose=False):\n",
        "    sims_list = []\n",
        "    \n",
        "    #calculate prediction\n",
        "    preds = model.predict(V_val, verbose=0)[0]\n",
        "    \n",
        "    #calculate vector for each candidate\n",
        "    for candidate in candidate_list:\n",
        "        #calculate vector\n",
        "        #print(\"calculate vector for : \", candidate[1])\n",
        "        V = np.array(d2v_model.infer_vector(candidate[1]))\n",
        "        #calculate csonie similarity\n",
        "        sim = scipy.spatial.distance.cosine(V,preds)\n",
        "        #populate list of similarities\n",
        "        sims_list.append(sim)\n",
        "    \n",
        "    #select index of the biggest similarity\n",
        "    m = max(sims_list)\n",
        "    index_max = sims_list.index(m)\n",
        "    \n",
        "    if verbose == True :\n",
        "        print(\"selected phrase :\")\n",
        "        print(\"     \", candidate_list[index_max][0])\n",
        "    return candidate_list[index_max]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xO1ho3bzIvD",
        "colab_type": "text"
      },
      "source": [
        "# 3. Text generation - workflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmIAkBUtzIvE",
        "colab_type": "text"
      },
      "source": [
        "The following function, **generate_paragraph()**, combines all previous functions to generate the text.\n",
        "\n",
        "With the following parameters:\n",
        " - phrase_seed : the sentence seed for the first word prediction. It is a list of words.\n",
        " - sentences_seed : the seed sequence of sentences. It is a list of sentences.\n",
        " - max_words: the maximum number of words for a new generated sentence.\n",
        " - nb_words_in_seq: the number of words to keep as seed for the next word prediction.\n",
        " - temperature: the temperature for the word prediction.\n",
        " - nb_phrases: the number of phrase (sentence) to generate.\n",
        " - nb_candidates_sents: the number of phrase candidates to generate for each new phrase.\n",
        " - verbose: verbosity of the script.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "FbdpMuDzzIvF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_paragraphe(phrase_seed, sentences_seed, \\\n",
        "                        max_words = 50, \\\n",
        "                        nb_words_in_seq=20, \\\n",
        "                        temperature=1, \\\n",
        "                        nb_phrases=30, \\\n",
        "                        nb_candidates_sents=10, \\\n",
        "                        verbose=True):\n",
        "    \n",
        "    sentences_list = sentences_seed\n",
        "    sentence = phrase_seed   \n",
        "    text = []\n",
        "    \n",
        "    for p in range(nb_phrases):\n",
        "        if verbose == True : print(\"\")\n",
        "        if verbose == True : print(\"#############\")\n",
        "        print(\"phrase \",p+1, \"/\", nb_phrases)\n",
        "        if verbose == True : print(\"#############\")       \n",
        "        if verbose == True:\n",
        "            print('Sentence to generate phrase : ')\n",
        "            print(\"     \", sentence)\n",
        "            print(\"\")\n",
        "            print('List of sentences to constrain next phrase : ')\n",
        "            print(\"     \", sentences_list)\n",
        "            print(\"\")\n",
        "    \n",
        "        #generate seed training vector\n",
        "        V_val = generate_training_vector(sentences_list, verbose = verbose)\n",
        "\n",
        "        #generate phrase candidate\n",
        "        if verbose == True : print(\"generate phrases candidates...\")\n",
        "        phrases_candidates = define_phrases_candidates(sentence, \\\n",
        "                                                       max_words = max_words, \\\n",
        "                                                       nb_words_in_seq = nb_words_in_seq, \\\n",
        "                                                       temperature=temperature, \\\n",
        "                                                       nb_candidates_sents=nb_candidates_sents, \\\n",
        "                                                       verbose = verbose)\n",
        "        \n",
        "        if verbose == True : print(\"select next phrase...\")\n",
        "        next_phrase = select_next_phrase(model_sequence, \\\n",
        "                                         V_val,\n",
        "                                         phrases_candidates, \\\n",
        "                                         verbose=verbose)\n",
        "        \n",
        "        print(\"Next phrase: \",next_phrase[0])\n",
        "        if verbose == True :\n",
        "            print(\"\")\n",
        "            print(\"Shift phrases in sentences list...\")\n",
        "        for i in range(len(sentences_list)-1):\n",
        "            sentences_list[i]=sentences_list[i+1]\n",
        "\n",
        "        sentences_list[len(sentences_list)-1] = next_phrase[0]\n",
        "        \n",
        "        if verbose == True:\n",
        "            print(\"done.\")\n",
        "            print(\"new list of sentences :\")\n",
        "            print(\"     \", sentences_list)     \n",
        "        sentence = next_phrase[1]\n",
        "        \n",
        "        text.append(next_phrase[0])\n",
        "    \n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNCFHbkAzIvU",
        "colab_type": "text"
      },
      "source": [
        "Now, we can perform the complete text generation workflow.\n",
        "\n",
        "First, we have to define the sentences in the seed (15 phrases):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "W-wV_GWRzIvV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s1 = \"nolan s' approche du bord du chemin et regarde en contrebas .\"\n",
        "s2 = \"il se tourne vers mara :\"\n",
        "s3 = \"- que dis tu ?\"\n",
        "s4 = \"- rien du tout , lui répond la jeune femme en détournant le regard .\"\n",
        "s5 = \"- je t' ai entendu dire quelque chose , pourtant .\"\n",
        "s6 = \"- je pensais à voix haute , explique mara  .\"\n",
        "s7 = \"l' apprentie hésite , elle n' est pas certaine que nolan comprenne .\"\n",
        "s8 = \"depuis quelques jours , nolan est à fleur de peau et s'inquiète pour un rien .\"\n",
        "s9 = \"- je crois avoir vu une ombre , déclare finalement la jeune femme .\"\n",
        "s10 = \"- à quel endroit ?\"\n",
        "s11 = \"s' écrie le jeune homme .\"\n",
        "s12 = \"nolan semble bouleversé et il est devenu blanc de peur .\"\n",
        "s13 = \"les souvenirs des kaurocs sont suffisament frais dans sa mémoire pour qu' une étrange angoisse lui noue la poitrine .\"\n",
        "s14 = \"- ne sois pas inquiet , s' exclame mara , confuse de la réaction de son ami .\"\n",
        "s15 = \"il y a probablement une erreur .\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5723PM2zIvg",
        "colab_type": "text"
      },
      "source": [
        "We combine them in a list:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhHGt7Y_zIvh",
        "colab_type": "code",
        "colab": {},
        "outputId": "32f54a3a-f2df-4b7f-d8bb-aa07bfb2703a"
      },
      "source": [
        "sentences_list = [s1,s2,s3,s4,s5,s6,s7,s8,s9,s10,s11,s12,s13,s14,s15]\n",
        "print(sentences_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\"nolan s' approche du bord du chemin et regarde en contrebas .\", 'il se tourne vers mara :', '- que dis tu ?', '- rien du tout , lui répond la jeune femme en détournant le regard .', \"- je t' ai entendu dire quelque chose , pourtant .\", '- je pensais à voix haute , explique mara  .', \"l' apprentie hésite , elle n' est pas certaine que nolan comprenne .\", \"depuis quelques jours , nolan est à fleur de peau et s'inquiète pour un rien .\", '- je crois avoir vu une ombre , déclare finalement la jeune femme .', '- à quel endroit ?', \"s' écrie le jeune homme .\", 'nolan semble bouleversé et il est devenu blanc de peur .', \"les souvenirs des kaurocs sont suffisament frais dans sa mémoire pour qu' une étrange angoisse lui noue la poitrine .\", \"- ne sois pas inquiet , s' exclame mara , confuse de la réaction de son ami .\", 'il y a probablement une erreur .']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJOjG1X_zIvo",
        "colab_type": "text"
      },
      "source": [
        "We concatenate them in a single phrase and create the seed sentence:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pW6aqUfSzIvp",
        "colab_type": "code",
        "colab": {},
        "outputId": "bca3f121-299f-4948-eb11-b2b34802a237"
      },
      "source": [
        "phrase_seed, sentences_seed = create_seed(s1 + \" \" + s2 + \" \" +\\\n",
        "                                          s3 + \" \" + s4+ \" \" + s5 + \" \" +\\\n",
        "                                          s6 + \" \" + s7 + \" \" + s8 + \" \" +\\\n",
        "                                          s9+ \" \" + s10 + \" \" + s11 + \" \" +\\\n",
        "                                          s12 + \" \" + s13 + \" \" + s14+ \" \" + s15,20)\n",
        "print(phrase_seed)\n",
        "print(sentences_seed)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ", s' exclame mara , confuse de la réaction de son ami . il y a probablement une erreur .\n",
            "[',', \"s'\", 'exclame', 'mara', ',', 'confuse', 'de', 'la', 'réaction', 'de', 'son', 'ami', '.', 'il', 'y', 'a', 'probablement', 'une', 'erreur', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qnr_fNrIzIvt",
        "colab_type": "text"
      },
      "source": [
        "Run the script to generate the text !"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oz4dxRoGzIvv",
        "colab_type": "code",
        "colab": {},
        "outputId": "d4eeed02-7b3a-43d3-dd23-a0c15e1f9447"
      },
      "source": [
        "text = generate_paragraphe(sentences_seed, sentences_list, \\\n",
        "                           max_words = 80, \\\n",
        "                           nb_words_in_seq = 30,\\\n",
        "                           temperature=0.201, \\\n",
        "                           nb_phrases=5, \\\n",
        "                           nb_candidates_sents=7, \\\n",
        "                           verbose=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "phrase  1 / 5\n",
            "Next phrase:   — oui , c’ est que ce que vous êtes à l’ attaque de ces monstres …\n",
            "phrase  2 / 5\n",
            "Next phrase:   nolan se tourne vers mara qui se racle la gorge .\n",
            "phrase  3 / 5\n",
            "Next phrase:   — c’ est un peu de temps !\n",
            "phrase  4 / 5\n",
            "Next phrase:   panicaut se tourne vers silvi .\n",
            "phrase  5 / 5\n",
            "Next phrase:   — c’ est vrai , renchérit lothar , c’ est une chose que vous êtes tous les trois porteurs …\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zYnS9p5zIvz",
        "colab_type": "text"
      },
      "source": [
        "Then, the new text generated is:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDTwZjjTzIv0",
        "colab_type": "code",
        "colab": {},
        "outputId": "a7c3aa39-2412-4768-d670-432b65794557"
      },
      "source": [
        "print(\"generated text: \")\n",
        "for t in text:\n",
        "    print(t)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "generated text: \n",
            " — oui , c’ est que ce que vous êtes à l’ attaque de ces monstres …\n",
            " nolan se tourne vers mara qui se racle la gorge .\n",
            " — c’ est un peu de temps !\n",
            " panicaut se tourne vers silvi .\n",
            " — c’ est vrai , renchérit lothar , c’ est une chose que vous êtes tous les trois porteurs …\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "fs3OknvHzIv9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}